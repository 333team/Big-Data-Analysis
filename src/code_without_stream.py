# ==============================================================================
# 2025 æ•™è‚²å¤§æ•¸æ“šç«¶è³½ï¼šå®Œæ•´åˆ†æè…³æœ¬ (æœ€çµ‚å®šç¨¿ç‰ˆ)
# éšŠåï¼šä¸‰ä¸‰ä¸‰æ—…
# åŠŸèƒ½ï¼šEDAã€ANOVA æª¢å®šã€Random Forest é æ¸¬èˆ‡æ‡‰ç”¨æ¨¡æ“¬
# ==============================================================================
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import font_manager
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report
from sklearn.preprocessing import LabelEncoder
import statsmodels.api as sm
from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm
import warnings

# å¿½ç•¥ä¸å¿…è¦çš„è­¦å‘Š
warnings.filterwarnings('ignore')

# ==============================================================================
# 1. ç’°å¢ƒè¨­å®šèˆ‡è³‡æ–™è®€å–
# ==============================================================================
print("ğŸš€ [Step 1] åˆå§‹åŒ–èˆ‡è®€å–è³‡æ–™...")

# --- è¨­å®šå­—é«” (è§£æ±ºä¸­æ–‡äº‚ç¢¼) ---
font_file = "../resource/NotoSansTC-Regular.ttf"
if os.path.exists(font_file):
    my_font = font_manager.FontProperties(fname=font_file)
    # è¨­å®šå…¨åŸŸå­—é«”
    plt.rcParams['font.sans-serif'] = ['Noto Sans TC']
    plt.rcParams['axes.unicode_minus'] = False
    print("âœ… å­—é«”è¼‰å…¥æˆåŠŸã€‚")
else:
    my_font = None
    print("âš ï¸ è­¦å‘Šï¼šæ‰¾ä¸åˆ°ä¸­æ–‡å­—é«”æª”ï¼Œåœ–è¡¨æ–‡å­—å¯èƒ½ç„¡æ³•æ­£å¸¸é¡¯ç¤ºã€‚")

# --- æ¬„ä½åç¨±å°ç…§ (ä¾æ“šæ‚¨çš„è³‡æ–™) ---
FILE_PATH = '../resource/anonymized_file0115.csv'
COL_USER = 'å­¸ç”Ÿå§“åå»è­˜åˆ¥åŒ–'
COL_START_TIME = 'ä»»å‹™æ´¾ç™¼æ™‚é–“'
COL_END_TIME = 'å­¸ç”Ÿé¦–æ¬¡é€å‡ºç­”æ¡ˆçš„æ™‚é–“é»'
COL_SCORE = 'é¦–æ¬¡ç­”é¡Œæ­£ç¢ºç‡'
COL_DURATION = 'é¦–æ¬¡ç­”é¡Œæ™‚é–“ï¼ˆç§’ï¼‰'
COL_DIFFICULTY = 'é›£æ˜“åº¦'
COL_TASK_NAME = 'ä»»å‹™åç¨±'

try:
    df = pd.read_csv(FILE_PATH)
    print(f"âœ… è®€å–æˆåŠŸï¼ŒåŸå§‹è³‡æ–™å…± {len(df)} ç­†ã€‚")

    # --- è³‡æ–™æ¸…ç†èˆ‡ç‰¹å¾µå·¥ç¨‹ ---
    # 1. æ™‚é–“æ ¼å¼è½‰æ›
    df[COL_START_TIME] = pd.to_datetime(df[COL_START_TIME], errors='coerce')
    df[COL_END_TIME] = pd.to_datetime(df[COL_END_TIME], errors='coerce')

    # 2. ç§»é™¤ç„¡æ•ˆè³‡æ–™ (æ’é™¤æ™‚é–“ç¼ºå¤±æˆ–éæ•¸å€¼è³‡æ–™)
    df = df.dropna(subset=[COL_START_TIME, COL_END_TIME, COL_SCORE, COL_DURATION])

    # 3. è¨ˆç®—æ™‚é–“å»¶é² (Practice Lag)
    df['lag_hours'] = (df[COL_END_TIME] - df[COL_START_TIME]) / pd.Timedelta(hours=1)

    # 4. é—œéµå€é–“é–å®š (0~168å°æ™‚ï¼Œæ’é™¤æ¥µç«¯å€¼èˆ‡é‡è¤‡ä½œç­”å¹²æ“¾)
    df_final = df[(df['lag_hours'] >= 0) & (df['lag_hours'] <= 168)].copy()

    # 5. ç¢ºä¿æ•¸å€¼æ ¼å¼
    df_final[COL_SCORE] = pd.to_numeric(df_final[COL_SCORE], errors='coerce')
    df_final[COL_DURATION] = pd.to_numeric(df_final[COL_DURATION], errors='coerce')

    print(f"âœ… æ¸…ç†å®Œæˆï¼Œå‰©é¤˜ {len(df_final)} ç­†æœ‰æ•ˆåˆ†æè³‡æ–™ã€‚")

    # --- å­¸ç¿’è€…èƒ½åŠ›åˆ†ç¾¤ (Learner Grouping) ---
    # ä½¿ç”¨ä¸­ä½æ•¸åˆ‡åˆ†æ³• (Median Split)
    user_stats = df_final.groupby(COL_USER)[COL_SCORE].mean()
    median_score = user_stats.median()


    def get_group(user_id):
        s = user_stats.get(user_id)
        if s is None: return 'æœªçŸ¥'
        return 'é«˜åˆ†çµ„' if s >= median_score else 'æ½›åŠ›çµ„'


    df_final['student_group'] = df_final[COL_USER].apply(get_group)
    print(f"â„¹ï¸ å­¸ç”Ÿåˆ†ç¾¤åŸºæº– (ä¸­ä½æ•¸): {median_score:.2f}")

    # --- å°æ•¸åˆ†ç®± (Log Binning) ---
    # ç”¨æ–¼è¦–è¦ºåŒ–å­¸ç¿’åˆæœŸçš„ç´°å¾®è®ŠåŒ–
    log_bins = [0] + list(np.logspace(0, 7, num=8, base=2)) + [168]
    log_labels = [f'{log_bins[i]:.1f}-{log_bins[i + 1]:.1f}h' for i in range(len(log_bins) - 1)]
    df_final['log_lag_bin'] = pd.cut(df_final['lag_hours'], bins=log_bins, labels=log_labels, right=False)

except Exception as e:
    print(f"âŒ è³‡æ–™è™•ç†ç™¼ç”ŸéŒ¯èª¤: {e}")
    df_final = None

# ==============================================================================
# 2. è¦–è¦ºåŒ– (EDA) - åœ– F-1 & F-2
# ==============================================================================
if df_final is not None:
    print("\nğŸš€ [Step 2] ç¹ªè£½æ¢ç´¢æ€§åˆ†æåœ–è¡¨...")
    sns.set_style("whitegrid")

    # --- åœ– F-1: æ­£ç¢ºç‡ ---
    plt.figure(figsize=(16, 8))
    ax1 = sns.barplot(
        data=df_final, x='log_lag_bin', y=COL_SCORE, hue='student_group',
        palette={'é«˜åˆ†çµ„': 'dodgerblue', 'æ½›åŠ›çµ„': 'salmon'}, errorbar=('ci', 95)
    )
    plt.title('åœ– F-1: ä¸åŒèƒ½åŠ›çµ„åœ¨ã€Œå°æ•¸æ™‚é–“å»¶é²ã€ä¸‹çš„å¹³å‡æ­£ç¢ºç‡ (CI=95%)', fontsize=16, fontproperties=my_font)
    plt.xlabel('ä»»å‹™æ´¾ç™¼åˆ°é¦–æ¬¡ä½œç­”çš„é–“éš” (å°æ™‚)', fontsize=12, fontproperties=my_font)
    plt.ylabel('é¦–æ¬¡ç­”é¡Œæ­£ç¢ºç‡', fontsize=12, fontproperties=my_font)
    plt.xticks(rotation=45)

    # ä¿®å¾©åœ–ä¾‹äº‚ç¢¼
    if my_font:
        L = plt.legend(title='å­¸ç”Ÿåˆ†çµ„', prop=my_font)
        plt.setp(L.get_title(), fontproperties=my_font)
    plt.show()

    # --- åœ– F-2: ç­”é¡Œè€—æ™‚ (æ ¸å¿ƒäº®é») ---
    plt.figure(figsize=(16, 8))
    ax2 = sns.barplot(
        data=df_final, x='log_lag_bin', y=COL_DURATION, hue='student_group',
        palette={'é«˜åˆ†çµ„': 'dodgerblue', 'æ½›åŠ›çµ„': 'salmon'}, errorbar=('ci', 95)
    )
    plt.title('åœ– F-2: ä¸åŒèƒ½åŠ›çµ„åœ¨ã€Œå°æ•¸æ™‚é–“å»¶é²ã€ä¸‹çš„å¹³å‡ç­”é¡Œè€—æ™‚ (ç§’)', fontsize=16, fontproperties=my_font)
    plt.xlabel('ä»»å‹™æ´¾ç™¼åˆ°é¦–æ¬¡ä½œç­”çš„é–“éš” (å°æ™‚)', fontsize=12, fontproperties=my_font)
    plt.ylabel('å¹³å‡é¦–æ¬¡ç­”é¡Œæ™‚é–“ (ç§’)', fontsize=12, fontproperties=my_font)
    plt.xticks(rotation=45)

    # ä¿®å¾©åœ–ä¾‹äº‚ç¢¼
    if my_font:
        L = plt.legend(title='å­¸ç”Ÿåˆ†çµ„', prop=my_font)
        plt.setp(L.get_title(), fontproperties=my_font)
    plt.show()

# ==============================================================================
# 3. çµ±è¨ˆæª¢å®š (ANOVA)
# ==============================================================================
if df_final is not None:
    print("\nğŸš€ [Step 3] åŸ·è¡Œé›™å› å­è®Šç•°æ•¸åˆ†æ (Two-way ANOVA)...")

    # æº–å‚™ä¹¾æ·¨çš„è³‡æ–™çµ¦ statsmodels
    df_stat = df_final.copy()
    df_stat = df_stat.rename(columns={
        COL_DURATION: 'Duration',
        COL_SCORE: 'Score',
        'student_group': 'Group',
        'log_lag_bin': 'TimeBin'
    })

    # æª¢å®šç­”é¡Œæ™‚é–“ (Duration) çš„äº¤äº’ä½œç”¨
    model_duration = ols('Duration ~ C(Group) + C(TimeBin) + C(Group):C(TimeBin)', data=df_stat).fit()
    anova_table = anova_lm(model_duration, typ=2)
    p_val = anova_table.loc['C(Group):C(TimeBin)', 'PR(>F)']
    f_val = anova_table.loc['C(Group):C(TimeBin)', 'F']

    print("\nğŸ“Š ç­”é¡Œæ™‚é–“ ANOVA çµæœ (äº¤äº’ä½œç”¨):")
    print(f"   F-Value: {f_val:.2f}")
    print(f"   P-Value: {p_val:.4e}")
    if p_val < 0.05:
        print("âœ… çµæœï¼šé¡¯è‘—ï¼è­‰å¯¦é«˜åˆ†çµ„èˆ‡æ½›åŠ›çµ„çš„è¡Œç‚ºæ¨¡å¼å…·å‚™çµ±è¨ˆé¡¯è‘—å·®ç•°ã€‚")
    else:
        print("âš ï¸ çµæœï¼šæœªé”é¡¯è‘—æ°´æº–ã€‚")

# ==============================================================================
# 4. AI é æ¸¬æ¨¡å‹èˆ‡æ‡‰ç”¨ (Random Forest V2.0)
# ==============================================================================
if df_final is not None:
    print("\nğŸš€ [Step 4] å•Ÿå‹•ç‰¹å¾µå·¥ç¨‹èˆ‡æ¨¡å‹å„ªåŒ– (V2.0)...")

    # --- 4.1 é€²éšç‰¹å¾µå·¥ç¨‹ (Advanced Feature Engineering) ---
    df_model = df_final.copy()

    # ç‰¹å¾µ A: å­¸ç”ŸåŸºç¤èƒ½åŠ› (User Ability)
    df_model['user_ability'] = df_model.groupby(COL_USER)[COL_SCORE].transform('mean')

    # ç‰¹å¾µ B: é¡Œç›®çœŸå¯¦é›£åº¦ (Real Task Difficulty)
    df_model['task_pass_rate'] = df_model.groupby(COL_TASK_NAME)[COL_SCORE].transform('mean')

    # ç‰¹å¾µ C: æ™‚é–“çš„éç·šæ€§è®Šæ› (Log Lag)
    df_model['log_lag'] = np.log1p(df_model['lag_hours'])

    # ç‰¹å¾µ D: åŸå§‹é›£åº¦ç·¨ç¢¼
    le = LabelEncoder()
    df_model['diff_code'] = le.fit_transform(df_model[COL_DIFFICULTY].astype(str))

    # --- 4.2 å®šç¾©ç›®æ¨™èˆ‡è¨“ç·´ ---
    # å®šç¾©ç›®æ¨™ï¼šéœ€è¦å¹«åŠ© (æ­£ç¢ºç‡ < 80)
    target_threshold = 80 if df_final[COL_SCORE].max() > 1 else 0.8
    df_model['need_help'] = np.where(df_model[COL_SCORE] < target_threshold, 1, 0)

    feature_cols = ['lag_hours', 'log_lag', 'diff_code', 'user_ability', 'task_pass_rate']
    df_model = df_model.dropna(subset=feature_cols)

    X = df_model[feature_cols]
    y = df_model['need_help']

    # åˆ‡åˆ†è³‡æ–™ (80% è¨“ç·´, 20% æ¸¬è©¦)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

    # è¨“ç·´éš¨æ©Ÿæ£®æ— (åƒæ•¸å„ªåŒ–)
    clf = RandomForestClassifier(
        n_estimators=300,
        max_depth=15,
        min_samples_leaf=5,
        random_state=42,
        class_weight='balanced',
        n_jobs=-1
    )
    clf.fit(X_train, y_train)

    # é æ¸¬
    y_pred = clf.predict(X_test)
    y_prob = clf.predict_proba(X_test)[:, 1]

    # --- 4.3 ç¹ªè£½åœ– H-1: æ··æ·†çŸ©é™£ (ç¶ è‰²ç‰ˆ) ---
    cm = confusion_matrix(y_test, y_pred)

    # è¨ˆç®— Recall (å¬å›ç‡)
    tp = cm[1, 1]
    fn = cm[1, 0]
    recall = tp / (tp + fn)
    print(f"ğŸ“Š æ¨¡å‹å¬å›ç‡ (Recall): {recall:.2%} (æˆåŠŸæ•æ‰é«˜é¢¨éšªå­¸ç”Ÿçš„æ¯”ä¾‹)")

    plt.figure(figsize=(8, 6))
    ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',
                     xticklabels=['é æ¸¬:é€šé', 'é æ¸¬:éœ€å¹«åŠ©'],
                     yticklabels=['å¯¦éš›:é€šé', 'å¯¦éš›:éœ€å¹«åŠ©'])
    plt.title('åœ– H-1 (å„ªåŒ–ç‰ˆ): é æ¸¬æ¨¡å‹æ··æ·†çŸ©é™£', fontsize=16, fontproperties=my_font)
    plt.xlabel('æ¨¡å‹é æ¸¬', fontsize=12, fontproperties=my_font)
    plt.ylabel('çœŸå¯¦æƒ…æ³', fontsize=12, fontproperties=my_font)
    # å¼·åˆ¶è¨­å®šè»¸åˆ»åº¦å­—é«”
    plt.xticks(fontproperties=my_font)
    plt.yticks(fontproperties=my_font)
    plt.show()

    # --- 4.4 ç¹ªè£½åœ– H-2: ROC æ›²ç·š ---
    fpr, tpr, _ = roc_curve(y_test, y_prob)
    roc_auc = auc(fpr, tpr)

    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='darkgreen', lw=2, label=f'Optimized Model (AUC = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')
    plt.title('åœ– H-2 (å„ªåŒ–ç‰ˆ): æ¨¡å‹é‘‘åˆ¥åŠ›åˆ†æ', fontsize=16, fontproperties=my_font)
    plt.xlabel('False Positive Rate', fontsize=12)
    plt.ylabel('True Positive Rate', fontsize=12)
    plt.legend(loc="lower right")
    plt.show()

    # --- 4.5 ç¹ªè£½åœ– G-1: ç‰¹å¾µé‡è¦æ€§ ---
    importances = clf.feature_importances_
    indices = np.argsort(importances)[::-1]
    sorted_features = [feature_cols[i] for i in indices]
    sorted_importances = importances[indices]

    plt.figure(figsize=(10, 6))
    sns.barplot(x=sorted_importances, y=sorted_features, palette='viridis')
    plt.title('åœ– G-1 (å„ªåŒ–ç‰ˆ): é—œéµå½±éŸ¿å› å­æ’å', fontsize=16, fontproperties=my_font)
    plt.xlabel('é‡è¦æ€§æ¬Šé‡', fontsize=12, fontproperties=my_font)
    # yè»¸æ¨™ç±¤å¯èƒ½éœ€è¦èªªæ˜ï¼Œé€™è£¡ä¿æŒè‹±æ–‡è®Šæ•¸åä»¥å…äº‚ç¢¼ï¼Œä½†å¯åœ¨å ±å‘Šä¸­è§£é‡‹
    plt.show()

    # ==========================================================================
    # 5. æ‡‰ç”¨æ¨¡æ“¬ (Scenario Demo)
    # ==========================================================================
    print("\nğŸš€ [Step 5] æ™ºæ…§è¤‡ç¿’ç³»çµ±ï¼šæƒ…å¢ƒæ¨¡æ“¬ Demo")
    print("-" * 60)

    # 5.1 è‡ªå‹•æœå°‹æœ€ä½³ç¯„ä¾‹ (å°‹æ‰¾é«˜é¢¨éšªçš„æ½›åŠ›å­¸ç”Ÿ)
    df_search = df_model.copy()
    df_search['risk_prob'] = clf.predict_proba(X)[:, 1]

    # æ¢ä»¶ï¼šä¸­ç­‰ç¨‹åº¦å­¸ç”Ÿ(0.4~0.7) + æ‹–å»¶è¶…é2å¤© + é¢¨éšªæ¥µé«˜
    target_group = df_search[
        (df_search['user_ability'] >= 0.4) &
        (df_search['user_ability'] <= 0.7) &
        (df_search['lag_hours'] > 48)
        ].sort_values(by='risk_prob', ascending=False)

    if len(target_group) > 0:
        case_study = target_group.iloc[0]
        # é‚„åŸé›£åº¦æ–‡å­—
        try:
            real_diff_text = le.inverse_transform([int(case_study['diff_code'])])[0]
        except:
            real_diff_text = str(case_study['diff_code'])

        print(f"ğŸ”¥ æƒ…å¢ƒ B (å±éšª - éºå¿˜è­¦ç¤º):")
        print(f"   - ä»»å‹™é›£åº¦: ã€Œ{real_diff_text}ã€")
        print(f"   - å­¸ç”Ÿç¨‹åº¦: {case_study['user_ability'] * 100:.1f} åˆ† (ä¸­ç­‰ç¨‹åº¦)")
        print(f"   - å»¶é²æ™‚é–“: {case_study['lag_hours']:.1f} å°æ™‚ (ç´„ {case_study['lag_hours'] / 24:.1f} å¤©)")
        print(f" -> AI é æ¸¬å¤±æ•—é¢¨éšª: {case_study['risk_prob'] * 100:.1f}%")
        print("ğŸ”´ ç³»çµ±å»ºè­°ï¼šã€ç«‹å³è¤‡ç¿’ã€‘(åµæ¸¬åˆ°éºå¿˜é¢¨éšªé£†å‡)")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°æ¥µç«¯é«˜é¢¨éšªæ¡ˆä¾‹ï¼Œè«‹åƒè€ƒåœ–è¡¨çµæœã€‚")
    print("-" * 60)

print("\nâœ… æ‰€æœ‰åˆ†æåŸ·è¡Œå®Œç•¢ï¼ç¥æ¯”è³½é †åˆ©ï¼")